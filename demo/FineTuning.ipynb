{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a888278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25839/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d59c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec8e1",
   "metadata": {},
   "source": [
    "## Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81722caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIR=../../data2\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  239M  100  239M    0     0   171M      0  0:00:01  0:00:01 --:--:--  171M\n",
      "Archive:  age-prediction-nti-sbebank-2019.zip\n",
      "  inflating: ../../data2/test.csv    \n",
      "  inflating: ../../data2/small_group_description.csv  \n",
      "  inflating: ../../data2/train_target.csv  \n",
      "  inflating: ../../data2/transactions_train.csv  \n",
      "  inflating: ../../data2/transactions_test.csv  \n",
      "load_source_data       : Loaded 26450577 rows from \"/mnt/mikheev/data2/transactions_train.csv\"\n",
      "load_source_data       : Loaded 17667328 rows from \"/mnt/mikheev/data2/transactions_test.csv\"\n",
      "load_source_data       : Loaded 44117905 rows in total\n",
      "trx_to_features        : Found 50000 unique clients\n",
      "_td_float              : To-float time transformation\n",
      "trx_to_features        : Encoder stat for \"trans_date\":\n",
      "codes | trx_count\n",
      "                cnt  % of total\n",
      "trans_date                     \n",
      "[1, 80)     5951516    0.134900\n",
      "[80, 160)   5604756    0.127040\n",
      "[160, 240)  5417575    0.122798\n",
      "[240, 319)  5062781    0.114756\n",
      "[319, 399)  4848380    0.109896\n",
      "[399, 479)  4628310    0.104908\n",
      "[479, 558)  4327300    0.098085\n",
      "[558, 638)  4121286    0.093415\n",
      "[638, 718)  3679116    0.083393\n",
      "[718, 731)   476885    0.010809\n",
      "trx_to_features        : Encoder stat for \"small_group\":\n",
      "codes | trx_count\n",
      "                  cnt  % of total\n",
      "small_group                      \n",
      "[1, 9)       32108067    0.727779\n",
      "[9, 17)       5509832    0.124889\n",
      "[17, 26)      1886282    0.042755\n",
      "[26, 34)      1262772    0.028623\n",
      "[34, 43)      1093213    0.024779\n",
      "[43, 51)       689710    0.015633\n",
      "[51, 60)       558961    0.012670\n",
      "[60, 68)       296880    0.006729\n",
      "[68, 77)       251340    0.005697\n",
      "[77, 205)      460848    0.010446\n",
      "trx_to_features        : Encoder stat for \"amount_rur\":\n",
      "codes | trx_count\n",
      "                 cnt    % of total\n",
      "amount_rur                        \n",
      "[0.0, 0.1)   2334726  5.292015e-02\n",
      "[0.1, 0.2)  15353608  3.480131e-01\n",
      "[0.2, 0.3)  18118056  4.106735e-01\n",
      "[0.3, 0.4)   6900956  1.564208e-01\n",
      "[0.4, 0.5)   1201589  2.723586e-02\n",
      "[0.5, 0.6)    183599  4.161553e-03\n",
      "[0.6, 0.7)     23142  5.245489e-04\n",
      "[0.7, 0.8)      2034  4.610373e-05\n",
      "[0.8, 0.9)       185  4.193309e-06\n",
      "[0.9, 1.0)         9  2.039988e-07\n",
      "trx_to_features        : Trx count per clients:\n",
      "len(trx_list) | client_count\n",
      "               cnt  % of total\n",
      "trx_count                     \n",
      "[700, 749)    8419     0.16838\n",
      "[749, 798)    7659     0.15318\n",
      "[798, 847)    6782     0.13564\n",
      "[847, 896)    5996     0.11992\n",
      "[896, 945)    5283     0.10566\n",
      "[945, 994)    4595     0.09190\n",
      "[994, 1043)   4093     0.08186\n",
      "[1043, 1092)  3546     0.07092\n",
      "[1092, 1142)  3094     0.06188\n",
      "[1142, 1151)   533     0.01066\n",
      "trx_to_features        : Feature collection in progress ...\n",
      "trx_to_features        : Feature names: ['trans_date', 'small_group', 'amount_rur']\n",
      "trx_to_features        : Prepared features for 50000 clients\n",
      "update_with_target     : Target loaded for 30000 clients\n",
      "update_with_target     : Target updated for 50000 clients\n",
      "split_dataset          : Train size: 47000 clients\n",
      "split_dataset          : Test size: 3000 clients\n",
      "save_features          : Saved to: \"/mnt/mikheev/data2/train_trx.p\"\n",
      "save_features          : Saved to: \"/mnt/mikheev/data2/test_trx.p\"\n",
      "<module>               : Data collected in 152 sec (0:02:32.261236)\n"
     ]
    }
   ],
   "source": [
    "%env DATA_DIR=../../data2\n",
    "! mkdir $DATA_DIR\n",
    "! curl -OL https://storage.googleapis.com/di-datasets/age-prediction-nti-sbebank-2019.zip\n",
    "! unzip -j -o age-prediction-nti-sbebank-2019.zip 'data/*.csv' -d $DATA_DIR\n",
    "! mv age-prediction-nti-sbebank-2019.zip $DATA_DIR\n",
    "\n",
    "!python ../make_datasets.py \\\n",
    "    --data_path $DATA_DIR\\\n",
    "    --trx_files transactions_train.csv transactions_test.csv \\\n",
    "    --col_client_id \"client_id\" \\\n",
    "    --cols_event_time \"#float\" \"trans_date\" \\\n",
    "    --cols_category \"trans_date\" \"small_group\" \\\n",
    "    --cols_log_norm \"amount_rur\" \\\n",
    "    --target_files train_target.csv \\\n",
    "    --col_target bins \\\n",
    "    --test_size 0.1 \\\n",
    "    --output_train_path \"$DATA_DIR/train_trx.p\" \\\n",
    "    --output_test_path \"$DATA_DIR/test_trx.p\" \\\n",
    "    --output_test_ids_path \"$DATA_DIR/test_ids.csv\" \\\n",
    "    --log_file \"$DATA_DIR/dataset_age_pred.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b807d",
   "metadata": {},
   "source": [
    "## Embedding training\n",
    "\n",
    "Model training in our framework organised via pytorch-lightning (pl) framework.\n",
    "The key parts of neural networks training in pl are: \n",
    "\n",
    "    * model (pl.LightningModule)\n",
    "    * data_module (pl.LightningDataModule)\n",
    "    * pl.trainer (pl.trainer)\n",
    "    \n",
    "For futher details check https://www.pytorchlightning.ai/\n",
    "\n",
    "### model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d56474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhocon import ConfigFactory\n",
    "from dltranz.lightning_modules.coles_module import CoLESModule\n",
    "\n",
    "\n",
    "model_params = '''\n",
    "    validation_metric_params: {\n",
    "      K: 4,\n",
    "      metric: cosine\n",
    "    },\n",
    "    \n",
    "    encoder_type: rnn,\n",
    "    rnn: {\n",
    "      type: gru,\n",
    "      hidden_size: 160,\n",
    "      bidir: false,\n",
    "      trainable_starter: static\n",
    "    },\n",
    "    \n",
    "    head_layers: [\n",
    "      [Linear, {\"in_features\": \"{seq_encoder.embedding_size}\", \"out_features\": 256}],\n",
    "      [BatchNorm1d, {num_features: 256}],\n",
    "      [ReLU, {}],\n",
    "      [Linear, {\"in_features\": 256, \"out_features\": 256}],\n",
    "      [NormEncoder, {}]\n",
    "    ],\n",
    "    \n",
    "    transf: {\n",
    "      shared_layers: false,\n",
    "      input_size: 64,\n",
    "      n_heads: 2,\n",
    "      dim_hidden: 64,\n",
    "      dropout: 0.1,\n",
    "      n_layers: 4,\n",
    "      max_seq_len: 1,\n",
    "      use_after_mask: false,\n",
    "      use_positional_encoding: false,\n",
    "    },\n",
    "\n",
    "    trx_encoder: {\n",
    "      norm_embeddings: false,\n",
    "      embeddings_noise: 0.003\n",
    "      embeddings: {\n",
    "        trans_date: {in: 800, out: 16}\n",
    "        small_group: {in: 250, out: 16}\n",
    "      }\n",
    "      numeric_values: {\n",
    "        amount_rur: identity\n",
    "      }\n",
    "    }\n",
    "\n",
    "    lr_scheduler: {\n",
    "      step_size: 30\n",
    "      step_gamma: 0.9025\n",
    "    }\n",
    "\n",
    "    train: {\n",
    "      sampling_strategy: HardNegativePair\n",
    "      neg_count: 5\n",
    "      loss: ContrastiveLoss\n",
    "      margin: 0.5\n",
    "      lr: 0.002\n",
    "      weight_decay: 0.0\n",
    "    }\n",
    "'''\n",
    "\n",
    "\n",
    "model = CoLESModule(ConfigFactory.parse_string(model_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cab65",
   "metadata": {},
   "source": [
    "### Data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bfc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load.data_module.coles_data_module import ColesDataModuleTrain\n",
    "\n",
    "dm_params = '''\n",
    "    type: map\n",
    "    setup: {\n",
    "      col_id: client_id\n",
    "      dataset_files: {\n",
    "        data_path: \"data/train_trx_file.parquet\"\n",
    "      }\n",
    "      split_by: files\n",
    "      valid_size: 0.1\n",
    "      valid_split_seed: 42\n",
    "    }\n",
    "    train: {\n",
    "      min_seq_len: 25\n",
    "      augmentations: [\n",
    "        [DropoutTrx, {trx_dropout: 0.01}]\n",
    "      ]\n",
    "      buffer_size: 512\n",
    "      split_strategy: {\n",
    "        split_strategy: \"SampleSlices\"\n",
    "        split_count: 5\n",
    "        cnt_min: 25\n",
    "        cnt_max: 600\n",
    "      }\n",
    "      num_workers: 16\n",
    "      batch_size: 512\n",
    "    }\n",
    "    valid: {\n",
    "      augmentations: []\n",
    "      split_strategy: {\n",
    "        split_strategy: SampleSlices\n",
    "        split_count: 5\n",
    "        cnt_min: 25\n",
    "        cnt_max: 100\n",
    "      }\n",
    "      num_workers: 16\n",
    "      batch_size: 1024\n",
    "    }\n",
    "'''\n",
    "\n",
    "dm = ColesDataModuleTrain(ConfigFactory.parse_string(dm_params), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc2b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
